{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "import gc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/vmaithel')\n",
    "\n",
    "g = 9.8 #[m s^-2]\n",
    "L = 2.26e6 #[J/kg]\n",
    "cp = 1005 #[J/kg-K]\n",
    "R_e = 6.378e6 #[m]\n",
    "pi = 22/7\n",
    "\"\"\"\n",
    "local scripts, if loading from a different directory include that with a '.' between\n",
    "directory name and script name\n",
    "\"\"\"\n",
    "from tropical_PODs.PODs.POD_utils import limit_files_to_select_years\n",
    "from tropical_PODs.PODs.POD_utils import calculate_one_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import calculate_two_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import calculate_two_variable_binned_coevolution_composites\n",
    "from tropical_PODs.PODs.POD_utils import process_multiyear_one_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import process_multiyear_two_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import process_multiyear_two_variable_binned_coevolution_composites\n",
    "from tropical_PODs.PODs.plotting_utils import plot_one_variable_binned_ivar\n",
    "from tropical_PODs.PODs.plotting_utils import plot_two_variables_binned_ivar\n",
    "from tropical_PODs.PODs.POD_utils import numerical_plume_model\n",
    "from tropical_PODs.PODs.POD_utils import calculate_CAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_in_data(input_file, xarray_name, start_year, end_year, lat_lbound, lat_ubound, upper_level, lower_level):\n",
    "    \n",
    "    paths = glob(input_file)\n",
    "    year_limited_paths = limit_files_to_select_years(paths,range(start_year,end_year+1))\n",
    "    dataset = xr.open_mfdataset(year_limited_paths, combine=\"by_coords\")\n",
    "    dataset = dataset.sortby('lat', ascending=True)\n",
    "\n",
    "    if 'level' in dataset.dims:\n",
    "        data_var = dataset[xarray_name].sel(time = slice(str(start_year)+'-01-01', str(end_year)+'-12-31'), lat = slice(lat_lbound,lat_ubound), level = slice(upper_level, lower_level))\n",
    "    else: \n",
    "        data_var = dataset[xarray_name].sel(time = slice(str(start_year)+'-01-01', str(end_year)+'-12-31'), lat = slice(lat_lbound,lat_ubound))\n",
    "\n",
    "    data_var.load()\n",
    "\n",
    "    return dataset, data_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input directories and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years to analyze\n",
    "start_year = (2011)\n",
    "end_year = (2012)\n",
    "\n",
    "################\n",
    "###.  ERA5.  ###\n",
    "################\n",
    "\n",
    "# Atmosphere\n",
    "\n",
    "ifile_specific_humidity = '/Projects/era5_regrid/2p5_benedict/ERA5_2.5deg_daily/shum.2p5.*.nc' # ERA5 Specific Humidity\n",
    "ifile_temperature = '/Projects/era5_regrid/2p5_benedict/ERA5_2.5deg_daily/air.2p5.*.nc' # ERA5 Temperature\n",
    "ifile_surface_pressure = '/Projects/era5_regrid/2p5_benedict/ERA5_2.5deg_daily/pres.sfc.2p5.*.nc' # ERA5 Surface Pressure\n",
    "ifile_precipitation = '/Projects/era5_regrid/IMERG/3B-DAY.MS.MRG.3IMERG.V06.*' # IMERG Precipitation\n",
    "\n",
    "# Land\n",
    "ifile_land_frac = '/Projects/era5_regrid/2p5_vijit/ERAi_landfrac_2p5.nc' # ERAi Land Fraction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory for datasets\n",
    "odir_datasets = '/home/vmaithel/MSE_budgets/cape_data/'\n",
    "\n",
    "# Output directory for plots\n",
    "odir_plots = '/home/vmaithel/plots/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:   (lat: 73, lon: 144)\n",
      "Coordinates:\n",
      "  * lat       (lat) float32 -90.0 -87.5 -85.0 -82.5 ... 82.5 85.0 87.5 90.0\n",
      "  * lon       (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
      "Data variables:\n",
      "    landfrac  (lat, lon) float64 ...\n",
      "<xarray.DataArray 'landfrac' (lat: 73, lon: 144)>\n",
      "array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]])\n",
      "Coordinates:\n",
      "  * lat      (lat) float32 -90.0 -87.5 -85.0 -82.5 -80.0 ... 82.5 85.0 87.5 90.0\n",
      "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
      "Attributes:\n",
      "    Units:    Fraction of land, 0 = all water, 1 = all land\n"
     ]
    }
   ],
   "source": [
    "paths_land = glob(ifile_land_frac)\n",
    "dataset_land = xr.open_dataset(paths_land[0])\n",
    "print(dataset_land)\n",
    "land_sea_mask = dataset_land['landfrac']\n",
    "land_sea_mask.load()\n",
    "print(land_sea_mask)\n",
    "\n",
    "#landfrac = land_sea_mask.rename({'Latitude':'lat','Longitude':'lon'})\n",
    "#landfrac = landfrac.rename('landfrac')\n",
    "#print(landfrac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3951309/3855986173.py:100: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  precipitation_rate['time'] = precipitation_rate.indexes['time'].to_datetimeindex() # IMERG time was saved as CFtime, and we need to convert to datetime for xarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying landfrac as needed\n",
      "Calculating true model pressure\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-10., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -10.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-7.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -7.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-5., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -5.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-2.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -2.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(0., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 0.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(2.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 2.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(5., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 5.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(7.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 7.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(10., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 10.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "2012\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3951309/3855986173.py:100: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  precipitation_rate['time'] = precipitation_rate.indexes['time'].to_datetimeindex() # IMERG time was saved as CFtime, and we need to convert to datetime for xarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying landfrac as needed\n",
      "Calculating true model pressure\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-10., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -10.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-7.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -7.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-5., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -5.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(-2.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 -2.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(0., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 0.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(2.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 2.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(5., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 5.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(7.5, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 7.5\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n",
      "<xarray.DataArray 'lat' ()>\n",
      "array(10., dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float32 10.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "    \n",
    "g = 9.8 # [m s^-2]\n",
    "\n",
    "#########################################\n",
    "# Define paths of files we wish to load #\n",
    "#########################################\n",
    "    \n",
    "# glob expands paths with * to a list of files, like the unix shell #\n",
    "\n",
    "paths_specific_humidity = glob(ifile_specific_humidity)\n",
    "paths_temperature = glob(ifile_temperature)\n",
    "paths_surface_pressure = glob(ifile_surface_pressure)\n",
    "paths_precipitation = glob(ifile_precipitation)\n",
    "paths_land = glob(ifile_land_frac)\n",
    "        \n",
    "for year in range(start_year, end_year + 1):\n",
    "        \n",
    "    print(year)\n",
    "\n",
    "    # Define year strings #\n",
    "\n",
    "    previous_year_string = str(year - 1)\n",
    "    current_year_string = str(year)\n",
    "    next_year_string = str(year + 1)\n",
    "            \n",
    "    while len(previous_year_string) < 4:\n",
    "        previous_year_string = '0' + previous_year_string\n",
    "                \n",
    "    while len(current_year_string) < 4:\n",
    "        current_year_string = '0' + current_year_string\n",
    "                \n",
    "    while len(next_year_string) < 4:\n",
    "        next_year_string = '0' + next_year_string\n",
    "\n",
    "    # Limit paths to previous, current, and next year #\n",
    "\n",
    "    year_limited_paths_specific_humidity = limit_files_to_select_years(paths_specific_humidity, range(year - 1, year + 2))\n",
    "    year_limited_paths_temperature = limit_files_to_select_years(paths_temperature, range(year - 1, year + 2))\n",
    "    year_limited_paths_surface_pressure = limit_files_to_select_years(paths_surface_pressure, range(year - 1, year + 2))\n",
    "    year_limited_paths_precipitation = limit_files_to_select_years(paths_precipitation, range(year - 1, year + 2))\n",
    "\n",
    "    print(len(year_limited_paths_specific_humidity))\n",
    "     \n",
    "    #####################\n",
    "    ####  Load Data  ####\n",
    "    #####################\n",
    "\n",
    "    # Data is \"lazy loaded\", nothing is actually loaded until we \"look\" at data in some way #\n",
    "\n",
    "    dataset_specific_humidity = xr.open_mfdataset(year_limited_paths_specific_humidity, combine=\"by_coords\")\n",
    "    dataset_temperature = xr.open_mfdataset(year_limited_paths_temperature, combine=\"by_coords\")\n",
    "    dataset_surface_pressure = xr.open_mfdataset(year_limited_paths_surface_pressure, combine=\"by_coords\")\n",
    "    dataset_precipitation = xr.open_mfdataset(year_limited_paths_precipitation, combine=\"by_coords\")\n",
    "    dataset_land = xr.open_dataset(paths_land[0])\n",
    "\n",
    "    #####################\n",
    "    ####  Load Data  ####\n",
    "    #####################\n",
    "              \n",
    "    # Make data arrays, loading only the year of interest #\n",
    "    full_lat = dataset_surface_pressure['lat']\n",
    "    full_lon = dataset_surface_pressure['lon']\n",
    "    landfrac = dataset_land['landfrac']\n",
    "\n",
    "    PS = dataset_surface_pressure['pres'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'), lat = slice(-10, 10)) # [Pa]\n",
    "    Q = dataset_specific_humidity['shum'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'),lat = slice(10, -10), level = slice(70, 1000)) # [Kg/Kg]\n",
    "    T = dataset_temperature['air'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'),lat = slice(10, -10), level = slice(70, 1000)) # [K]\n",
    "    precipitation_rate = dataset_precipitation['precipAvg'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'), lat = slice(-10, 10)) * (24) # Currently [mm/hr]. Convert to [mm/day]\n",
    "\n",
    "    # Actually load data #\n",
    "    landfrac.load()\n",
    "    PS.load()\n",
    "    Q.load()\n",
    "    T.load()\n",
    "    precipitation_rate.load()\n",
    "\n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    " \n",
    "    ################################\n",
    "    ####  Average Data to Daily ####\n",
    "    ################################\n",
    "    \n",
    "    ###   Test for Averaging Method   ###\n",
    "            \n",
    "    #PS.sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).plot()\n",
    "    #print(PS.resample(time='1D').mean('time').sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75))\n",
    "    #print(PS.sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).mean('time'))\n",
    "    #print(PS.resample(time='1D').mean('time').sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).values == PS.sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).mean('time').values)\n",
    "    \n",
    "    ###   Perform Averaging   ###\n",
    "            \n",
    "    PS = PS.resample(time='1D').mean('time')\n",
    "    Q = Q.resample(time='1D').mean('time')\n",
    "    T = T.resample(time='1D').mean('time')\n",
    "    precipitation_rate = precipitation_rate.resample(time='1D').mean('time')\n",
    "\n",
    "    precipitation_rate['time'] = precipitation_rate.indexes['time'].to_datetimeindex() # IMERG time was saved as CFtime, and we need to convert to datetime for xarray\n",
    "\n",
    "    # ### Update time to reflect center of daily average   ###\n",
    "    \n",
    "    # PS = PS.assign_coords({'time':PS['time']+pd.to_timedelta(10.5, unit='H')})\n",
    "    # Q = Q.assign_coords({'time':Q['time']+pd.to_timedelta(10.5, unit='H')})\n",
    "    # T = T.assign_coords({'time':T['time']+pd.to_timedelta(10.5, unit='H')})\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    ####  Modify \"landfrac\" Variable as Needed ####\n",
    "    ###############################################\n",
    "    \n",
    "    print(\"Modifying landfrac as needed\")\n",
    "\n",
    "    #landfrac = land_sea_mask.rename({'Latitude':'lat','Longitude':'lon'})\n",
    "    #landfrac = landfrac.rename('landfrac')\n",
    "    #print(landfrac)\n",
    "    \n",
    "    # The landfrac variable does not have lat/lon coordinates. Assign those of variables and check to make sure they make sense #\n",
    "    \n",
    "    #print(landfrac.coords['lat'])\n",
    "    #landfrac.coords['lat'] = full_lat.coords['lat']\n",
    "    #landfrac.coords['lon'] = full_lon.coords['lon']\n",
    "\n",
    "    #landfrac = landfrac.transpose()\n",
    "\n",
    "    landfrac = landfrac.sel(lat = slice(-10, 10)) \n",
    "    \n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "    \n",
    "    #####################################\n",
    "    ####  Modify variables as needed ####\n",
    "    #####################################\n",
    "    \n",
    "    PS = PS.rename('PS')\n",
    "    PS = PS.transpose('time','lat','lon')\n",
    "    PS = PS.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    #print(PS)\n",
    "    \n",
    "    Q = Q.rename({'level':'lev'})\n",
    "    Q = Q.rename('Q')\n",
    "    Q = Q.transpose('time','lev','lat','lon')\n",
    "    Q = Q.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    #print(Q)\n",
    "    \n",
    "    T = T.rename({'level':'lev'})\n",
    "    T = T.rename('T')\n",
    "    T = T.transpose('time','lev','lat','lon')\n",
    "    T = T.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    #print(T)\n",
    "\n",
    "    precipitation_rate = precipitation_rate.rename('precipitation_rate')\n",
    "    precipitation_rate = precipitation_rate.transpose('time','lat','lon')\n",
    "    precipitation_rate = precipitation_rate.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    \n",
    "    landfrac = landfrac.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    \n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "\n",
    "    #########################################\n",
    "    ####  Calculate True Model Pressure  ####\n",
    "    #########################################\n",
    "\n",
    "    print(\"Calculating true model pressure\")\n",
    "    \n",
    "    # Set upper most interface equal to uppermost level midpoint, and lowest interface equal to surface pressure.\n",
    "    # This will still permit the desired vertical integral, just choose appropriate upper and lower integration limits\n",
    "    \n",
    "    # Model level midpoint\n",
    "\n",
    "    true_pressure_midpoint = Q['lev'] * 100. # To convert to Pa\n",
    "    true_pressure_midpoint = true_pressure_midpoint.rename('true_pressure_midpoint_Pa')\n",
    "    true_pressure_midpoint = true_pressure_midpoint.expand_dims({'lat':Q['lat'], 'lon':Q['lon'], 'time':Q['time']})\n",
    "    true_pressure_midpoint = true_pressure_midpoint.transpose('time','lev','lat','lon')\n",
    "    \n",
    "    # Model level interfaces\n",
    "    \n",
    "    true_pressure_interface = np.empty((len(Q.time),len(Q.lat),len(Q.lon),len(Q.lev)+1))\n",
    "\n",
    "    for interface_level_counter in range(len(Q.lev) + 1):\n",
    "        if interface_level_counter == 0:\n",
    "            true_pressure_interface[:,:,:,interface_level_counter] = Q['lev'].isel(lev=0).values # Set upper most interface equal to uppermost level midpoint\n",
    "        elif interface_level_counter == (len(Q.lev)):\n",
    "            true_pressure_interface[:,:,:,interface_level_counter] = PS # Set lowest interface equal to surface pressure\n",
    "        else:\n",
    "            true_pressure_interface[:,:,:,interface_level_counter] = (Q['lev'].isel(lev=interface_level_counter-1).values + Q['lev'].isel(lev=interface_level_counter).values) / 2.,  # Set middle interfaces equal to half way points between level midpoints\n",
    "            \n",
    "    coords = {'time':Q['time'], 'lat':Q['lat'], 'lon':Q['lon'], 'ilev':np.arange(1,len(Q.lev) + 2)}\n",
    "    dims = ['time', 'lat', 'lon', 'ilev']\n",
    "    true_pressure_interface = xr.DataArray(true_pressure_interface,dims=dims,coords=coords) * 100. # To convert to Pa\n",
    "    true_pressure_interface.attrs['units'] = 'Pa'      \n",
    "    \n",
    "    true_pressure_interface = true_pressure_interface.transpose('time','ilev','lat','lon')\n",
    "\n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "\n",
    "    ######################################\n",
    "    ####  Instantiate CAPE Variables  ####\n",
    "    ######################################\n",
    "    \n",
    "    nan_data = np.zeros(np.shape(PS))\n",
    "    nan_data[:] = np.nan\n",
    "    coords = PS.coords\n",
    "    dims = PS.dims\n",
    " \n",
    "    CAPE_DIB_1000_to_600 = xr.DataArray(nan_data,coords=coords,dims=dims)\n",
    "    CAPE_NOMIX_1000_to_600 = xr.full_like(CAPE_DIB_1000_to_600,np.nan) # can't simply repeat use of nan_data, otherwise pointer indicates same variable\n",
    "    \n",
    "    # Name variables #\n",
    "\n",
    "    CAPE_DIB_1000_to_600.name = 'CAPE_DIB_1000_to_600'\n",
    "    CAPE_NOMIX_1000_to_600.name = 'CAPE_NOMIX_1000_to_600'\n",
    " \n",
    "    # Add desired attributes #\n",
    "\n",
    "    CAPE_DIB_1000_to_600.attrs['Units'] = '[J Kg^-1]'\n",
    "    CAPE_NOMIX_1000_to_600.attrs['Units'] = '[J Kg^-1]'\n",
    "    \n",
    "    ####################################\n",
    "    ####  Calculate Buoyancy Terms  ####\n",
    "    ####################################\n",
    "    \n",
    "    launch_level_hPa = 1000 # [hPa] per Fiaz's code. Must remain close to 1000 to maintain mass flux profile\n",
    "    \n",
    "    for latitude in CAPE_DIB_1000_to_600.lat:\n",
    "        \n",
    "        print(latitude)\n",
    "        \n",
    "        for longitude in CAPE_DIB_1000_to_600.lon:\n",
    "                            \n",
    "            ########################################\n",
    "            ####  Virtual Temperature Variables ####\n",
    "            ########################################\n",
    "                \n",
    "            temp_v_env, temp_v_plume_DIB, temp_v_plume_NOMIX, c_mix_DIB = numerical_plume_model(T.sel(lat=latitude,lon=longitude), Q.sel(lat=latitude,lon=longitude), 1000)\n",
    "\n",
    "            ##########################\n",
    "            ####  CAPE Variables  ####\n",
    "            ##########################\n",
    "    \n",
    "            # print('Calculating CAPE Variables')\n",
    "                \n",
    "            CAPE_DIB_1000_to_600.loc[dict(lat=latitude,lon=longitude)] = calculate_CAPE(temp_v_env, temp_v_plume_DIB, true_pressure_midpoint.sel(lat=latitude,lon=longitude), true_pressure_interface.sel(lat=latitude,lon=longitude), 100000, 60000)\n",
    "                \n",
    "            CAPE_NOMIX_1000_to_600.loc[dict(lat=latitude,lon=longitude)] = calculate_CAPE(temp_v_env, temp_v_plume_NOMIX, true_pressure_midpoint.sel(lat=latitude,lon=longitude), true_pressure_interface.sel(lat=latitude,lon=longitude), 100000, 60000)   \n",
    "        \n",
    "            # Clean up environment #\n",
    "    \n",
    "            gc.collect();\n",
    "        \n",
    "    #################################\n",
    "    ####  Output Data as NetCDF  ####\n",
    "    #################################\n",
    "\n",
    "    # Merge all neccessary dataarrays to a single dataset #\n",
    "\n",
    "    output_dataset = xr.merge([CAPE_DIB_1000_to_600, CAPE_NOMIX_1000_to_600])\n",
    "\n",
    "    # Output dataset to NetCDF #\n",
    "\n",
    "    output_dataset.sel(time = slice(current_year_string+'-01-01', current_year_string+'-12-31')).to_netcdf(odir_datasets + 'CAPE_variables_' + current_year_string + '.nc')\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
