{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "import gc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/vmaithel')\n",
    "\n",
    "g = 9.8 #[m s^-2]\n",
    "L = 2.26e6 #[J/kg]\n",
    "cp = 1005 #[J/kg-K]\n",
    "R_e = 6.378e6 #[m]\n",
    "pi = 22/7\n",
    "\"\"\"\n",
    "local scripts, if loading from a different directory include that with a '.' between\n",
    "directory name and script name\n",
    "\"\"\"\n",
    "from tropical_PODs.PODs.POD_utils import calculate_saturation_specific_humidity\n",
    "from tropical_PODs.PODs.POD_utils import mass_weighted_vertical_integral_w_nan\n",
    "from tropical_PODs.PODs.POD_utils import limit_files_to_select_years\n",
    "from tropical_PODs.PODs.POD_utils import calculate_one_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import calculate_two_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import calculate_two_variable_binned_coevolution_composites\n",
    "from tropical_PODs.PODs.POD_utils import process_multiyear_one_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import process_multiyear_two_variable_binned_ivar_composites\n",
    "from tropical_PODs.PODs.POD_utils import process_multiyear_two_variable_binned_coevolution_composites\n",
    "from tropical_PODs.PODs.plotting_utils import plot_one_variable_binned_ivar\n",
    "from tropical_PODs.PODs.plotting_utils import plot_two_variables_binned_ivar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input directories and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years to analyze\n",
    "start_year = (2011)\n",
    "end_year = (2012)\n",
    "\n",
    "################\n",
    "###.  ERA5.  ###\n",
    "################\n",
    "\n",
    "# Atmosphere\n",
    "\n",
    "ifile_specific_humidity = '/Projects/era5_regrid/2p5_benedict/ERA5_2.5deg_daily/shum.2p5.*.nc' # ERA5 Specific Humidity\n",
    "ifile_temperature = '/Projects/era5_regrid/2p5_benedict/ERA5_2.5deg_daily/air.2p5.*.nc' # ERA5 Temperature\n",
    "ifile_surface_pressure = '/Projects/era5_regrid/2p5_benedict/ERA5_2.5deg_daily/pres.sfc.2p5.*.nc' # ERA5 Surface Pressure\n",
    "ifile_precipitation = '/Projects/era5_regrid/IMERG/3B-DAY.MS.MRG.3IMERG.V06.*' # IMERG Precipitation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory for datasets\n",
    "odir_datasets = '/home/vmaithel/MSE_budgets/cape_data/'\n",
    "\n",
    "# Output directory for plots\n",
    "odir_plots = '/home/vmaithel/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4035930/718550265.py:96: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  precipitation_rate['time'] = precipitation_rate.indexes['time'].to_datetimeindex() # IMERG time was saved as CFtime, and we need to convert to datetime for xarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating true model pressure\n",
      "Calculating saturation specific humidity\n",
      "Column Integrating\n",
      "2012\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4035930/718550265.py:96: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  precipitation_rate['time'] = precipitation_rate.indexes['time'].to_datetimeindex() # IMERG time was saved as CFtime, and we need to convert to datetime for xarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating true model pressure\n",
      "Calculating saturation specific humidity\n",
      "Column Integrating\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "    \n",
    "g = 9.8 # [m s^-2]\n",
    "\n",
    "#########################################\n",
    "# Define paths of files we wish to load #\n",
    "#########################################\n",
    "    \n",
    "# glob expands paths with * to a list of files, like the unix shell #\n",
    "\n",
    "paths_specific_humidity = glob(ifile_specific_humidity)\n",
    "paths_temperature = glob(ifile_temperature)\n",
    "paths_surface_pressure = glob(ifile_surface_pressure)\n",
    "paths_precipitation = glob(ifile_precipitation)\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "        \n",
    "    print(year)\n",
    "\n",
    "    # Define year strings #\n",
    "\n",
    "    previous_year_string = str(year - 1)\n",
    "    current_year_string = str(year)\n",
    "    next_year_string = str(year + 1)\n",
    "            \n",
    "    while len(previous_year_string) < 4:\n",
    "        previous_year_string = '0' + previous_year_string\n",
    "                \n",
    "    while len(current_year_string) < 4:\n",
    "        current_year_string = '0' + current_year_string\n",
    "                \n",
    "    while len(next_year_string) < 4:\n",
    "        next_year_string = '0' + next_year_string\n",
    "\n",
    "    # Limit paths to previous, current, and next year #\n",
    "\n",
    "    year_limited_paths_specific_humidity = limit_files_to_select_years(paths_specific_humidity, range(year - 1, year + 2))\n",
    "    year_limited_paths_temperature = limit_files_to_select_years(paths_temperature, range(year - 1, year + 2))\n",
    "    year_limited_paths_surface_pressure = limit_files_to_select_years(paths_surface_pressure, range(year - 1, year + 2))\n",
    "    year_limited_paths_precipitation = limit_files_to_select_years(paths_precipitation, range(year - 1, year + 2))\n",
    "\n",
    "    print(len(year_limited_paths_specific_humidity))\n",
    "     \n",
    "    #####################\n",
    "    ####  Load Data  ####\n",
    "    #####################\n",
    "\n",
    "    # Data is \"lazy loaded\", nothing is actually loaded until we \"look\" at data in some way #\n",
    "\n",
    "    dataset_specific_humidity = xr.open_mfdataset(year_limited_paths_specific_humidity, combine=\"by_coords\")\n",
    "    dataset_temperature = xr.open_mfdataset(year_limited_paths_temperature, combine=\"by_coords\")\n",
    "    dataset_surface_pressure = xr.open_mfdataset(year_limited_paths_surface_pressure, combine = \"by_coords\")\n",
    "    dataset_precipitation = xr.open_mfdataset(year_limited_paths_precipitation, combine=\"by_coords\")\n",
    "\n",
    "    #####################\n",
    "    ####  Load Data  ####\n",
    "    #####################\n",
    "              \n",
    "    # Make data arrays, loading only the year of interest #\n",
    "    full_lat = dataset_surface_pressure['lat']\n",
    "    full_lon = dataset_surface_pressure['lon']\n",
    "\n",
    "    PS = dataset_surface_pressure['pres'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'), lat = slice(-10, 10)) # [Pa]\n",
    "    Q = dataset_specific_humidity['shum'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'),lat = slice(10, -10), level = slice(70, 1000)) # [Kg/Kg]\n",
    "    T = dataset_temperature['air'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'),lat = slice(10, -10), level = slice(70, 1000)) # [K]\n",
    "    precipitation_rate = dataset_precipitation['precipAvg'].sel(time = slice(previous_year_string+'-12-31', next_year_string+'-01-01'), lat = slice(-10, 10)) * (24) # Currently [mm/hr]. Convert to [mm/day]\n",
    "\n",
    "    # Actually load data #\n",
    "    PS.load()\n",
    "    Q.load()\n",
    "    T.load()\n",
    "    precipitation_rate.load()\n",
    "\n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    " \n",
    "    ################################\n",
    "    ####  Average Data to Daily ####\n",
    "    ################################\n",
    "    \n",
    "    ###   Test for Averaging Method   ###\n",
    "            \n",
    "    #PS.sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).plot()\n",
    "    #print(PS.resample(time='1D').mean('time').sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75))\n",
    "    #print(PS.sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).mean('time'))\n",
    "    #print(PS.resample(time='1D').mean('time').sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).values == PS.sel(time=slice('1998-01-01','1998-01-01'),lat=5,lon=75).mean('time').values)\n",
    "    \n",
    "    ###   Perform Averaging   ###\n",
    "            \n",
    "    PS = PS.resample(time='1D').mean('time')\n",
    "    Q = Q.resample(time='1D').mean('time')\n",
    "    T = T.resample(time='1D').mean('time')\n",
    "    precipitation_rate = precipitation_rate.resample(time='1D').mean('time')\n",
    "\n",
    "    precipitation_rate['time'] = precipitation_rate.indexes['time'].to_datetimeindex() # IMERG time was saved as CFtime, and we need to convert to datetime for xarray\n",
    "\n",
    "    # ### Update time to reflect center of daily average   ###\n",
    "    \n",
    "    # PS = PS.assign_coords({'time':PS['time']+pd.to_timedelta(10.5, unit='H')})\n",
    "    # Q = Q.assign_coords({'time':Q['time']+pd.to_timedelta(10.5, unit='H')})\n",
    "    # T = T.assign_coords({'time':T['time']+pd.to_timedelta(10.5, unit='H')})\n",
    "\n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "    \n",
    "    #####################################\n",
    "    ####  Modify variables as needed ####\n",
    "    #####################################\n",
    "    \n",
    "    PS = PS.rename('PS')\n",
    "    PS = PS.transpose('time','lat','lon')\n",
    "    PS = PS.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    #print(PS)\n",
    "    \n",
    "    Q = Q.rename({'level':'lev'})\n",
    "    Q = Q.rename('Q')\n",
    "    Q = Q.transpose('time','lev','lat','lon')\n",
    "    Q = Q.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    #print(Q)\n",
    "    \n",
    "    T = T.rename({'level':'lev'})\n",
    "    T = T.rename('T')\n",
    "    T = T.transpose('time','lev','lat','lon')\n",
    "    T = T.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "    #print(T)\n",
    "\n",
    "    precipitation_rate = precipitation_rate.rename('precipitation_rate')\n",
    "    precipitation_rate = precipitation_rate.transpose('time','lat','lon')\n",
    "    precipitation_rate = precipitation_rate.sortby('lat', ascending=True) # Re-order lat to match code for other datasets\n",
    "        \n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "\n",
    "    #########################################\n",
    "    ####  Calculate True Model Pressure  ####\n",
    "    #########################################\n",
    "\n",
    "    print(\"Calculating true model pressure\")\n",
    "    \n",
    "    # Set upper most interface equal to uppermost level midpoint, and lowest interface equal to surface pressure.\n",
    "    # This will still permit the desired vertical integral, just choose appropriate upper and lower integration limits\n",
    "    \n",
    "    # Model level midpoint\n",
    "\n",
    "    true_pressure_midpoint = Q['lev'] * 100. # To convert to Pa\n",
    "    true_pressure_midpoint = true_pressure_midpoint.rename('true_pressure_midpoint_Pa')\n",
    "    true_pressure_midpoint = true_pressure_midpoint.expand_dims({'lat':Q['lat'], 'lon':Q['lon'], 'time':Q['time']})\n",
    "    true_pressure_midpoint = true_pressure_midpoint.transpose('time','lev','lat','lon')\n",
    "    \n",
    "    # Model level interfaces\n",
    "    \n",
    "    true_pressure_interface = np.empty((len(Q.time),len(Q.lat),len(Q.lon),len(Q.lev)+1))\n",
    "\n",
    "    for interface_level_counter in range(len(Q.lev) + 1):\n",
    "        if interface_level_counter == 0:\n",
    "            true_pressure_interface[:,:,:,interface_level_counter] = Q['lev'].isel(lev=0).values # Set upper most interface equal to uppermost level midpoint\n",
    "        elif interface_level_counter == (len(Q.lev)):\n",
    "            true_pressure_interface[:,:,:,interface_level_counter] = PS # Set lowest interface equal to surface pressure\n",
    "        else:\n",
    "            true_pressure_interface[:,:,:,interface_level_counter] = (Q['lev'].isel(lev=interface_level_counter-1).values + Q['lev'].isel(lev=interface_level_counter).values) / 2.,  # Set middle interfaces equal to half way points between level midpoints\n",
    "            \n",
    "    coords = {'time':Q['time'], 'lat':Q['lat'], 'lon':Q['lon'], 'ilev':np.arange(1,len(Q.lev) + 2)}\n",
    "    dims = ['time', 'lat', 'lon', 'ilev']\n",
    "    true_pressure_interface = xr.DataArray(true_pressure_interface,dims=dims,coords=coords) * 100. # To convert to Pa\n",
    "    true_pressure_interface.attrs['units'] = 'Pa'      \n",
    "    \n",
    "    true_pressure_interface = true_pressure_interface.transpose('time','ilev','lat','lon')\n",
    "\n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "  \n",
    "    ########################\n",
    "    ###  Calculate CSF  ####\n",
    "    ########################\n",
    "    \n",
    "    ####  Calculate Saturation Specific Humidity  ####\n",
    "\n",
    "    print(\"Calculating saturation specific humidity\")\n",
    "\n",
    "    saturation_specific_humidity = xr.apply_ufunc(calculate_saturation_specific_humidity, true_pressure_midpoint, T,\n",
    "                                            output_dtypes=[Q.dtype])\n",
    "    \n",
    "    # Clean up environment #\n",
    "    \n",
    "    gc.collect();\n",
    "\n",
    "    ####  Column Integrate Variables  ####\n",
    "        \n",
    "    upper_level_integration_limit_Pa = 10000 # [Pa]\n",
    "        \n",
    "    lower_level_integration_limit_Pa = 100000 # [Pa]\n",
    "\n",
    "    print('Column Integrating')\n",
    "        \n",
    "    ci_q, _, _ = mass_weighted_vertical_integral_w_nan(Q, true_pressure_midpoint, true_pressure_interface, lower_level_integration_limit_Pa, upper_level_integration_limit_Pa)\n",
    "    #print(ci_q)\n",
    "    #print(ci_q.min())\n",
    "    #print(ci_q.max())\n",
    "    #print(ci_q.mean())\n",
    "    #plt.figure()\n",
    "    #ci_q.isel(time = 0).plot()\n",
    "        \n",
    "    ci_q_sat, _, _ = mass_weighted_vertical_integral_w_nan(saturation_specific_humidity, true_pressure_midpoint, true_pressure_interface, lower_level_integration_limit_Pa, upper_level_integration_limit_Pa)\n",
    "    #print(ci_q_sat)\n",
    "    #print(ci_q_sat.min())\n",
    "    #print(ci_q_sat.max())\n",
    "    #print(ci_q_sat.mean())\n",
    "    #plt.figure()\n",
    "    #ci_q_sat.isel(time = 0).plot()\n",
    "        \n",
    "    csf = ci_q / ci_q_sat\n",
    "    #print(csf)\n",
    "    #print(csf.min())\n",
    "    #print(csf.max())\n",
    "    #plt.figure()\n",
    "    #csf.isel(time = 0).plot()\n",
    "    \n",
    "    # Name variables #\n",
    "\n",
    "    csf.name = 'csf'\n",
    "    csf.attrs['Units'] = '[Kg Kg^-1]'\n",
    "\n",
    "    # Clean up environment #\n",
    "\n",
    "    del Q, T, true_pressure_midpoint, true_pressure_interface, saturation_specific_humidity, ci_q, ci_q_sat\n",
    "        \n",
    "    gc.collect();\n",
    "   \n",
    "    #################################\n",
    "    ####  Output Data as NetCDF  ####\n",
    "    #################################\n",
    "\n",
    "    # Output dataset to NetCDF #\n",
    "\n",
    "    csf.sel(time = slice(current_year_string+'-01-01', current_year_string+'-12-31')).to_netcdf(odir_datasets + 'CSF_' + current_year_string + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'lat' (lat: 9)>\n",
      "array([-10. ,  -7.5,  -5. ,  -2.5,   0. ,   2.5,   5. ,   7.5,  10. ],\n",
      "      dtype=float32)\n",
      "Coordinates:\n",
      "  * lat      (lat) float32 -10.0 -7.5 -5.0 -2.5 0.0 2.5 5.0 7.5 10.0\n",
      "Attributes:\n",
      "    long_name:  latitude\n",
      "    units:      degrees_north\n"
     ]
    }
   ],
   "source": [
    "print(csf.lat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
